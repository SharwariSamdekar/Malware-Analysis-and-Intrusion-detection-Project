from sklearn.metrics import confusion_matrix
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_selection import RFE
from sklearn.linear_model import LogisticRegression
import pandas as pd
import numpy as np
import pickle




dat = pd.read_csv("Features.csv", sep = ',', header = 0)
data = dat.sample(frac = 1)
data.head()


array = data.values
y = array[:,297]
x = array[:,:297]


# Selecting top 50 features
model = LogisticRegression(solver='lbfgs', max_iter = 1000)
rfe = RFE(model,50)
mfit = rfe.fit(x,y)

#Storing the reduced feature set
pickle.dump(mfit,open('reduce.txt','wb'))
print("Num Features: %d" % mfit.n_features_)
print("Selected Features: %s" % mfit.support_)
print("Feature Ranking: %s" % mfit.ranking_)

features = mfit.transform(x)

#Training Data
kf = ms.KFold(n_splits = 10,random_state = None, shuffle = True)
for train_index, test_index in kf.split(features) :
	X_train, X_test = features[train_index],features[test_index]
	Y_train, Y_test = y[train_index],y[test_index]
	cl = RandomForestClassifier(criterion = 'entropy',random_state = 0)
	cl = cl.fit(X_train,Y_train)
	ans = cl.predict(X_test)
	print(confusion_matrix(Y_test,ans))
	print(cl.score(X_test,Y_test))

cln = RandomForestClassifier(criterion='entropy',random_state = 0)
cln = cln.fit(features,y)

#Storing the model
pickle.dump(cln,open('model.txt','wb'))


#Testing the model using stored model
da = pd.read_csv("Test.csv", sep = ',', header = 0)
Testdata = da.sample(frac = 1)
Testdata.head()


load_reduce = pickle.load(open('reduce.txt','rb'))

load_model = pickle.load(open('model.txt','rb'))
Ty = np.array(Testdata.iloc[:,297])
Tx = np.array(Testdata.iloc[:,:297])

#Reduce the test features
Tfeatures = load_reduce.transform(Tx)
Tresult = (load_model.predict(Tfeatures))

print("len = ",len(Ty))


print(Tresult)
print(Ty)
print(load_model.score(Tfeatures,Ty))
print(confusion_matrix(Tresult,Ty))